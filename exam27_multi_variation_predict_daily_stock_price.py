# -*- coding: utf-8 -*-
"""exam27_multi_variation_predict_daily_stock_price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jNCwqAS7wQ424qbvU6iNpOhFW1uQ2RLt
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datetime
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping

raw_data = pd.read_csv('./datasets/samsung.csv')
print(raw_data.head())
print(raw_data.tail())
print(raw_data.info())

raw_data.dropna(inplace=True)
raw_data.reset_index(drop=True, inplace=True)
print(raw_data.info())

raw_data['Date'] = pd.to_datetime(raw_data['Date'])
raw_data.set_index('Date', inplace=True)
print(raw_data.head())

minmaxscaler = MinMaxScaler()
scaled_data = minmaxscaler.fit_transform(raw_data)
print(scaled_data[:5])
print(scaled_data.shape)

sequence_X = []
sequence_Y = []
for i in range(len(scaled_data)-30):
    x = scaled_data[i:i+30]
    y = scaled_data[i+30][3]
    sequence_X.append(x)
    sequence_Y.append(y)

sequence_X = np.array(sequence_X)
sequence_Y = np.array(sequence_Y)
print(sequence_X[0])
print(sequence_Y[0])
print(sequence_X.shape)
print(sequence_Y.shape)

last_test_data_X = sequence_X[-60:]
last_test_data_Y = sequence_Y[-60:]

X_train, X_test, Y_train, Y_test = train_test_split(
    sequence_X[:-30], sequence_Y[:-30], test_size=0.2)
xy = X_train, X_test, Y_train, Y_test, last_test_data_X, last_test_data_Y
np.save('./datasets/samsung_preprocessed_30.npy', xy)

X_train, X_test, Y_train, Y_test, last_test_data_X, last_test_data_Y \
= np.load('./datasets/samsung_preprocessed_30.npy', allow_pickle=True)

import pickle
with open('./samsung_stock_minmaxscaler.pickle', 'wb') as f:
    pickle.dump(minmaxscaler, f)

with open('./samsung_stock_minmaxscaler.pickle', 'rb') as f:
    minmaxscaler = pickle.load(f)

model = Sequential()
model.add(LSTM(50, input_shape=(30, 6),
               activation='tanh'))
model.add(Flatten())
model.add(Dense(1))
model.compile(loss='mse', optimizer='adam')
model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=30)
fit_hist = model.fit(X_train, Y_train, batch_size=200, epochs=500,
                     callbacks=[early_stopping], verbose=1,
                     shuffle = False, validation_data=(X_test, Y_test))

model.save('./models/samsung_multivariation.h5')

model = load_model('./models/samsung_multivariation.h5')

plt.plot(fit_hist.history['loss'][-450:], label='loss')
plt.plot(fit_hist.history['val_loss'][-450:], label='validation loss')
plt.legend()
plt.show()

predict = model.predict(X_test)

plt.plot(Y_test[-100:], label='actual')
plt.plot(predict[-100:], label='predict')
plt.legend()
plt.show()

last_predict = model.predict(last_test_data_X)

plt.plot(last_predict[-30:], label='predict')
plt.plot(last_test_data_Y[-30:], label='acture')
plt.legend()
plt.show()

tomorrow_predict = model.predict(
    last_test_data_X[-1].reshape(1, 30, 6))
print(tomorrow_predict)

minmaxscaler_close = MinMaxScaler()
minmaxscaler_close.fit_transform(raw_data[['Close']])

tomorrow_predicted_value = minmaxscaler_close.inverse_transform(
    tomorrow_predict)
print('%d Ïõê'%tomorrow_predicted_value[0][0])